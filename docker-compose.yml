version: '3'

x-spark-common: &spark-common
  build:
    context: .
    dockerfile: Dockerfile.spark
  command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  depends_on:
    - spark-master
  environment:
    SPARK_MODE: worker
    SPARK_WORKER_CORES: 2
    SPARK_WORKER_MEMORY: 1g
    SPARK_MASTER_URL: spark://spark-master:7077
  networks:
    - spark-network



services:
  spark-master:
    container_name: spark-master
    hostname: spark-master
    build:
      context: .
      dockerfile: Dockerfile.spark
    command: bin/spark-class org.apache.spark.deploy.master.Master
    volumes:
      - ./requirements.txt:/requirements.txt
    ports:
      - "9090:8080"
      - "7077:7077"
    networks:
      - spark-network

  spark-worker-1:
    <<: *spark-common
    container_name: spark-w-1
    hostname: spark-w-1
    volumes:
      - ./requirements.txt:/requirements.txt
  spark-worker-2:
    <<: *spark-common
    container_name: spark-w-2
    hostname: spark-w-2
    volumes:
      - ./requirements.txt:/requirements.txt


  hive:
    image: apache/hive:4.0.0
    ports:
      - "10000:10000"
    environment:
      - HIVE_PORT=10000
      - HIVE_METASTORE_PORT=9083
      - HIVE_CONF_javax_jdo_option_ConnectionURL=jdbc:derby:;databaseName=metastore_db;create=true
      - HIVE_CONF_hive_metastore_uris=thrift://localhost:9083
    depends_on:
      - metastore
    networks:
      - hive-network

  metastore:
    image: apache/hive:4.0.0
    ports:
      - "9083:9083"
    environment:
      - HIVE_METASTORE_PORT=9083
    networks:
      - hive-network


networks:
  spark-network:
  hive-network:

